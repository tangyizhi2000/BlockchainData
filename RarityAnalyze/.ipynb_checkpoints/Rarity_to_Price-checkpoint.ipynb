{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7a06758",
   "metadata": {},
   "source": [
    "# Rarity Analyse \n",
    "**created by yuteng_zeng on 4/23/2023**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99f55f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required library\n",
    "#!pip install web3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11052ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import json\n",
    "from web3 import Web3\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a404f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get api_interfaces by tangyizhi\n",
    "# API factors\n",
    "API_key = 'PlIE5PSJaLBOTy67DORlQwY3MchgQxfP'\n",
    "API_url = \"https://eth-mainnet.g.alchemy.com/v2/PlIE5PSJaLBOTy67DORlQwY3MchgQxfP\"\n",
    "API_nft_url = 'https://eth-mainnet.g.alchemy.com/nft/v2/PlIE5PSJaLBOTy67DORlQwY3MchgQxfP'\n",
    "\n",
    "# data collection functions\n",
    "def getNFTsForCollection(contractAddress, withMetadata):\n",
    "    url = API_url + '/getNFTsForCollection?contractAddress=' + contractAddress + '&withMetadata=' + str(withMetadata)\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r\n",
    "def getNFTSales(contractAddress, tokenid):\n",
    "    # from block 0 to latest block, with ascending order\n",
    "    url = API_url + '/getNFTSales?fromBlock=0&toBlock=latest&order=asc&contractAddress=' + contractAddress + '&tokenId=' + str(tokenid)\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r\n",
    "\n",
    "def getFloorPrice(contractAddress):\n",
    "    url = API_nft_url + \"/getFloorPrice?contractAddress=\" + contractAddress\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r\n",
    "\n",
    "def computeRarity(contractAddress, tokenid):\n",
    "    url = API_nft_url + '/computeRarity/?contractAddress=' + contractAddress + '&tokenId=' + str(tokenid)\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r\n",
    "\n",
    "def getMetaData(contractAddress, tokenid):\n",
    "    url = API_nft_url + '/getNFTMetadata?contractAddress=' + contractAddress + '&tokenId=' + str(tokenid) + '&refreshCache=false'\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r\n",
    "\n",
    "def getNFTAttributes(contractAddress):\n",
    "    url = API_nft_url + '/summarizeNFTAttributes?contractAddress=' + contractAddress\n",
    "    r = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb1813c",
   "metadata": {},
   "source": [
    "*The following is api test and further utils for data collection and prep*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a62a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contract': {'address': '0x60e4d786628fea6478f785a6d7e704777c86a7c6'}, 'id': {'tokenId': '0x0000000000000000000000000000000000000000000000000000000000000000', 'tokenMetadata': {'tokenType': 'ERC721'}}, 'title': '', 'description': '', 'tokenUri': {'gateway': 'https://boredapeyachtclub.com/api/mutants/0', 'raw': 'https://boredapeyachtclub.com/api/mutants/0'}, 'media': [{'gateway': 'https://nft-cdn.alchemy.com/eth-mainnet/c480d814f8a4e2b5f02dd3aa189ca742', 'thumbnail': 'https://res.cloudinary.com/alchemyapi/image/upload/thumbnailv2/eth-mainnet/c480d814f8a4e2b5f02dd3aa189ca742', 'raw': 'ipfs://QmURua8bNrAwX76Tp6G9t6Lospdxyt61JGy3UsXY7skfR1', 'format': 'png', 'bytes': 577530}], 'metadata': {'image': 'ipfs://QmURua8bNrAwX76Tp6G9t6Lospdxyt61JGy3UsXY7skfR1', 'attributes': [{'value': 'M1 Purple', 'trait_type': 'Background'}, {'value': 'M1 Cheetah', 'trait_type': 'Fur'}, {'value': 'M1 Scumbag', 'trait_type': 'Eyes'}, {'value': 'M1 Toga', 'trait_type': 'Clothes'}, {'value': 'M1 Bored Unshaven', 'trait_type': 'Mouth'}]}, 'timeLastUpdated': '2023-04-18T02:34:09.376Z', 'contractMetadata': {'name': 'MutantApeYachtClub', 'symbol': 'MAYC', 'totalSupply': '19468', 'tokenType': 'ERC721', 'contractDeployer': '0x9056d15c49b19df52ffad1e6c11627f035c0c960', 'deployedBlockNumber': 13117018, 'openSea': {'floorPrice': 15.5, 'collectionName': 'Mutant Ape Yacht Club', 'safelistRequestStatus': 'verified', 'imageUrl': 'https://i.seadn.io/gae/lHexKRMpw-aoSyB1WdFBff5yfANLReFxHzt1DOj_sg7mS14yARpuvYcUtsyyx-Nkpk6WTcUPFoG53VnLJezYi8hAs0OxNZwlw6Y-dmI?w=500&auto=format', 'description': 'The MUTANT APE YACHT CLUB is a collection of up to 20,000 Mutant Apes that can only be created by exposing an existing Bored Ape to a vial of MUTANT SERUM or by minting a Mutant Ape in the public sale.', 'lastIngestedAt': '2023-03-18T01:37:24.000Z'}}}\n"
     ]
    }
   ],
   "source": [
    "response = json.loads(getNFTsForCollection('0x60E4d786628Fea6478F785A6d7e704777c86a7c6', True).content)\n",
    "print(response['nfts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9957c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Fur', 'Eyes', 'Background', 'Mouth', 'Clothes', 'Earring', 'Hat', 'Name'])\n"
     ]
    }
   ],
   "source": [
    "# check the attribute lists.\n",
    "response = json.loads(getNFTAttributes('0x60E4d786628Fea6478F785A6d7e704777c86a7c6').content)\n",
    "print(response['summary'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0964fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'value': 'M1 Purple', 'trait_type': 'Background', 'prevalence': 0.09621621621621622}, {'value': 'M1 Cheetah', 'trait_type': 'Fur', 'prevalence': 0.03099099099099099}, {'value': 'M1 Scumbag', 'trait_type': 'Eyes', 'prevalence': 0.016885456885456885}, {'value': 'M1 Toga', 'trait_type': 'Clothes', 'prevalence': 0.01662805662805663}, {'value': 'M1 Bored Unshaven', 'trait_type': 'Mouth', 'prevalence': 0.11613899613899614}]\n"
     ]
    }
   ],
   "source": [
    "response = json.loads(computeRarity('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',0).content)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124d5764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'amount': '23740500000000000000', 'tokenAddress': '0x0000000000000000000000000000000000000000', 'symbol': 'ETH', 'decimals': 18}\n",
      "{'amount': '624750000000000000', 'tokenAddress': '0x0000000000000000000000000000000000000000', 'symbol': 'ETH', 'decimals': 18}\n",
      "{'amount': '624750000000000000', 'tokenAddress': '0x0000000000000000000000000000000000000000', 'symbol': 'ETH', 'decimals': 18}\n"
     ]
    }
   ],
   "source": [
    "response = json.loads(getNFTSales('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',555).content)\n",
    "print(response['nftSales'][-1]['sellerFee'])\n",
    "print(response['nftSales'][-1]['protocolFee'])\n",
    "print(response['nftSales'][-1]['royaltyFee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5941667d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.7405\n",
      "106.875\n"
     ]
    }
   ],
   "source": [
    "# get the sell price from the api\n",
    "def get_price(contractAddress, tokenid, roundto):\n",
    "    response = json.loads(getNFTSales(contractAddress,tokenid).content)\n",
    "    res = int(response['nftSales'][-1]['sellerFee']['amount'])/ (10**int(response['nftSales'][-1]['sellerFee']['decimals']))\n",
    "    res = round(res, roundto)\n",
    "    return res\n",
    "\n",
    "print(get_price('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',555,5))\n",
    "print(get_price('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',28905,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e4b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature and labels for building the dataset\n",
    "def get_monkey(contractAddress, tokenid, roundto):\n",
    "    # initialize all attributes to one, which means least rare\n",
    "    feature = {'Fur':1, 'Eyes':1, 'Background':1, 'Mouth':1, 'Clothes':1, 'Earring':1, 'Hat':1, 'Name':1}\n",
    "    feature_response = json.loads(computeRarity(contractAddress,tokenid).content)\n",
    "    #print(feature_response)\n",
    "    for i in feature_response:\n",
    "        feature[i['trait_type']] = round(1 / i['prevalence'], roundto)\n",
    "        \n",
    "    # get price\n",
    "    price = None\n",
    "    try:\n",
    "        price = get_price(contractAddress, tokenid, roundto)\n",
    "    except:\n",
    "        pass\n",
    "    return feature, price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470a212",
   "metadata": {},
   "source": [
    "there are monkeys that has never been traded, thus *try* get the price, \n",
    "\n",
    "if price donnot exist then the price is set to **None**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f477ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Fur': 9.95643, 'Eyes': 7.71752, 'Background': 10.76177, 'Mouth': 5.86327, 'Clothes': 33.31904, 'Earring': 1, 'Hat': 99.61538, 'Name': 1}, 20.9)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',2,5))\n",
    "print(get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',10000,5)[1] is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f02a50",
   "metadata": {},
   "source": [
    "make the dataset using the template ['Fur', 'Eyes', 'Background', 'Mouth', 'Clothes', 'Earring', 'Hat', 'Name'] as **features**\n",
    "\n",
    "seller price as **labels** to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df84425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nattribute_list = ['Fur', 'Eyes', 'Background', 'Mouth', 'Clothes', 'Earring', 'Hat', 'Name']\\nfeatures = []\\nlabels = []\\ntoken_id = 1\\nwhile len(labels) <= 150:    \\n    feature, price = get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',token_id, 5)\\n    if price is not None:\\n        features.append([feature[x] for x in attribute_list])\\n        labels.append(price)\\n    token_id += 1\\n    time.sleep(0.01)\\nprint(features, labels)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now gathering the data and build dataset\n",
    "'''\n",
    "attribute_list = ['Fur', 'Eyes', 'Background', 'Mouth', 'Clothes', 'Earring', 'Hat', 'Name']\n",
    "features = []\n",
    "labels = []\n",
    "token_id = 1\n",
    "while len(labels) <= 150:    \n",
    "    feature, price = get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',token_id, 5)\n",
    "    if price is not None:\n",
    "        features.append([feature[x] for x in attribute_list])\n",
    "        labels.append(price)\n",
    "    token_id += 1\n",
    "    time.sleep(0.01)\n",
    "print(features, labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a11dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwhile len(labels) < 1200:    \\n    feature, price = get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',token_id, 5)\\n    if price is not None:\\n        features.append([feature[x] for x in attribute_list])\\n        labels.append(price)\\n    token_id += 1\\n    time.sleep(0.01)\\nprint(features, labels)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only runone time to get data\n",
    "# partially acquire data... getting too fast would cause api denial\n",
    "'''\n",
    "while len(labels) < 1200:    \n",
    "    feature, price = get_monkey('0x60E4d786628Fea6478F785A6d7e704777c86a7c6',token_id, 5)\n",
    "    if price is not None:\n",
    "        features.append([feature[x] for x in attribute_list])\n",
    "        labels.append(price)\n",
    "    token_id += 1\n",
    "    time.sleep(0.01)\n",
    "print(features, labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e90cb7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cdc86e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(features), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04376084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata = []\\ndata.append(features)\\ndata.append(labels)\\nlen(data[1])\\nwith open('data_features_labels.pkl','wb') as f:\\n    pickle.dump(data, f)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store data in a pickle file\n",
    "'''\n",
    "data = []\n",
    "data.append(features)\n",
    "data.append(labels)\n",
    "len(data[1])\n",
    "with open('data_features_labels.pkl','wb') as f:\n",
    "    pickle.dump(data, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b59c817a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data_features_labels.pkl','rb') as f:\n",
    "    load_data = pickle.load(f)\n",
    "len(load_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d5650",
   "metadata": {},
   "source": [
    "With the data acquired, we can directly apply ML models to fit the data and do predictions, we can do so by **RandomForest**, which may be suitable for our data since the feature dimension is not large and can be seperately judged, perhaps. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c504c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing some of the results:\n",
      "preds: [15.4504133 20.0809271 10.7115035 12.9803584 19.218093  15.3320771\n",
      " 13.2271288 38.153786  13.6505272 13.3473243 12.5995639 17.5792\n",
      " 13.4893934 12.4509482 19.2247025 14.7334061 17.4171825 11.3171323\n",
      " 11.7479038 21.4716115]\n",
      "labels: [15.2, 5.225, 4.4175, 16.55375, 19.95, 19.0, 13.2692, 39.2, 16.235, 20.9, 5.8425, 15.2, 15.66455, 24.4055, 17.1, 8.5405, 9.785, 14.9625, 7.125, 29.925]\n",
      "MSE: 1208007.0499351316\n"
     ]
    }
   ],
   "source": [
    "# define feature and label\n",
    "seed = 98\n",
    "np.random.seed(seed)\n",
    "X = load_data[0]\n",
    "Y = load_data[1]\n",
    "# split data into train and test sets\n",
    "X_TRAIN, X_TEST, Y_TRAIN, Y_TEST = train_test_split(X,Y,test_size = 0.1, random_state = seed)\n",
    "# define randomforest model\n",
    "RF = RandomForestRegressor(n_estimators = 100, random_state = seed)\n",
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_TRAIN)\n",
    "# apply normalization to train and test sets\n",
    "X_TRAIN = scaler.transform(X_TRAIN)\n",
    "X_TEST = scaler.transform(X_TEST)\n",
    "RF.fit(X_TRAIN, Y_TRAIN)\n",
    "# make prediction on test set\n",
    "pred = RF.predict(X_TEST)\n",
    "# analyse model function\n",
    "mse = mean_squared_error(Y_TEST, pred)\n",
    "print('showing some of the results:')\n",
    "print('preds:', pred[:20])\n",
    "print('labels:', Y_TEST[:20])\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f56407",
   "metadata": {},
   "source": [
    "It seems that the features have more high-dimension relations, which can hardly be interpreted as decisiontree classification. We can do a **SVM** instead, to get more high-dimension features, as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8a38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing some of the results:\n",
      "preds: [13.97448599 16.50242358 13.79753067 14.0856291  16.28839131 17.11522885\n",
      " 14.48781127 18.647618   15.30622184 17.76094566 14.53069409 18.62429624\n",
      " 14.39255615 14.22981915 14.97823383 14.08298295 13.77782817 15.08508179\n",
      " 14.1815663  19.13894446]\n",
      "labels: [15.2, 5.225, 4.4175, 16.55375, 19.95, 19.0, 13.2692, 39.2, 16.235, 20.9, 5.8425, 15.2, 15.66455, 24.4055, 17.1, 8.5405, 9.785, 14.9625, 7.125, 29.925]\n",
      "MSE: 115.47965802546605\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel = 'rbf', C=1, gamma ='scale')\n",
    "svr.fit(X_TRAIN, Y_TRAIN)\n",
    "# make prediction on test set\n",
    "pred = svr.predict(X_TEST)\n",
    "# analyse model function\n",
    "mse = mean_squared_error(Y_TEST, pred)\n",
    "print('showing some of the results:')\n",
    "print('preds:', pred[:20])\n",
    "print('labels:', Y_TEST[:20])\n",
    "print('MSE:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4658a8",
   "metadata": {},
   "source": [
    "Much better!\n",
    "\n",
    "Or, we can build neural networks for this task:\n",
    "\n",
    "Perhaps starting with a **MLP** model.\n",
    "\n",
    "Then we need to implement the basic nn pipeline, including dataset management, network definition, training and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "851efab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "960 960\n",
      "120 120\n",
      "120 120\n"
     ]
    }
   ],
   "source": [
    "# load data for train/validate/test datasets\n",
    "feature_train = []\n",
    "label_train = []\n",
    "feature_validation = []\n",
    "label_validation = []\n",
    "feature_test = []\n",
    "label_test = []\n",
    "\n",
    "data_length = len(load_data[1])\n",
    "print(data_length)\n",
    "# train/validation/test = 8:1:1\n",
    "# divide id into 10 groups, to eliminate influence by time \n",
    "group = 10\n",
    "group_l = data_length/group\n",
    "for i in range(group):\n",
    "    for j in range(int(group_l)):\n",
    "        if j < 0.8*group_l:\n",
    "            feature_train.append(load_data[0][i * group + j])\n",
    "            label_train.append(load_data[1][i * group + j])\n",
    "        elif j < 0.9*group_l:\n",
    "            feature_validation.append(load_data[0][i * group + j])\n",
    "            label_validation.append(load_data[1][i * group + j])\n",
    "        else:\n",
    "            feature_test.append(load_data[0][i * group + j])\n",
    "            label_test.append(load_data[1][i * group + j])\n",
    "print(len(feature_train), len(label_train))\n",
    "print(len(feature_validation), len(label_validation))\n",
    "print(len(feature_test), len(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b6a87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntr_dataset = h5py.File(tr_name, 'a')\\nval_dataset = h5py.File(val_name, 'a')\\ntest_dataset = h5py.File(test_name, 'a')\\n\\n# load data into the dataset\\ntr_dataset['feature'] = feature_train\\ntr_dataset['label'] = label_train\\nval_dataset['feature'] = feature_validation\\nval_dataset['label'] = label_validation\\ntest_dataset['feature'] = feature_test\\ntest_dataset['label'] = label_test\\n\\ntr_dataset.close()\\nval_dataset.close()\\ntest_dataset.close()\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define datasets\n",
    "\n",
    "tr_name = 'tr_set.hdf5'\n",
    "val_name = 'val_set.hdf5'\n",
    "test_name = 'test_set.hdf5'\n",
    "'''\n",
    "tr_dataset = h5py.File(tr_name, 'a')\n",
    "val_dataset = h5py.File(val_name, 'a')\n",
    "test_dataset = h5py.File(test_name, 'a')\n",
    "\n",
    "# load data into the dataset\n",
    "tr_dataset['feature'] = feature_train\n",
    "tr_dataset['label'] = label_train\n",
    "val_dataset['feature'] = feature_validation\n",
    "val_dataset['label'] = label_validation\n",
    "test_dataset['feature'] = feature_test\n",
    "test_dataset['label'] = label_test\n",
    "\n",
    "tr_dataset.close()\n",
    "val_dataset.close()\n",
    "test_dataset.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be24ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader\n",
    "batch_size = 30\n",
    "\n",
    "class dataset_pipeline(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super(dataset_pipeline, self).__init__()\n",
    "        self.h5pyLoader = h5py.File(path, 'r')\n",
    "        self.feature = self.h5pyLoader['feature']\n",
    "        self.label = self.h5pyLoader['label']\n",
    "        self.len_ = len(self.label)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        feature_item = torch.from_numpy(np.array(self.feature[index]).astype(np.float32))\n",
    "        label_item = self.label[index]\n",
    "        return feature_item, label_item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da98397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the datasets\n",
    "train_loader = DataLoader(dataset_pipeline(tr_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = True\n",
    "                         )\n",
    "val_loader = DataLoader(dataset_pipeline(val_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False\n",
    "                         )\n",
    "test_loader = DataLoader(dataset_pipeline(test_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b90abc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the MLP model\n",
    "class RP_MLP(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(RP_MLP, self).__init__()\n",
    "        \n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_unit = 16\n",
    "        self.output = 1\n",
    "        \n",
    "        self.layer1 = nn.Sequential(nn.Linear(self.feature_dim, self.hidden_unit),\n",
    "                                    nn.Sigmoid()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(nn.Linear(self.hidden_unit, self.hidden_unit),\n",
    "                                    nn.Sigmoid()\n",
    "        )\n",
    "        self.layer3 = nn.Linear(self.hidden_unit, self.output)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        output = self.layer1(input)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dfcb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def train(model, loader, opt, loss_fn):\n",
    "    '''\n",
    "    Training Step, called once per epoch.\n",
    "    Model is updated.\n",
    "    args:\n",
    "        model: nn.Module\n",
    "        loader: torch DataLoader\n",
    "        opt: torch.optim\n",
    "        loss_fn: differentiable loss_fn(probs, labels) -> scalar\n",
    "    return:\n",
    "        average training loss for this epoch\n",
    "    '''\n",
    "    model = model.train()\n",
    "    train_loss_batch = []\n",
    "    for batch_id, [data, labels] in enumerate(loader):\n",
    "        opt.zero_grad()\n",
    "        output = model(data)\n",
    "        output = output.float()\n",
    "        labels = labels.float()\n",
    "        loss = loss_fn(output.flatten(), labels)       \n",
    "        train_loss_batch.append(loss)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    train_loss_epoch = sum(train_loss_batch) / len(train_loss_batch)\n",
    "    return float(train_loss_epoch)\n",
    "\n",
    "def validate(model, loader, criterion, return_results = False):\n",
    "    '''\n",
    "    Validation Step, called once per epoch.\n",
    "    args:\n",
    "        model: nn.Module\n",
    "        loader: torch DataLoader\n",
    "        criterion: criterion(predicts, labels) -> scalar\n",
    "    return:\n",
    "        average accuracy of all frames, and if return_results,\n",
    "        (predicted probabalities, predicted labels)\n",
    "    \n",
    "    '''\n",
    "    model = model.eval()  \n",
    "    all_labels = torch.tensor([])\n",
    "    all_preds = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for batch_id, [data, labels] in enumerate(loader):\n",
    "            pred = model(data)\n",
    "            all_labels = torch.cat([all_labels, labels])\n",
    "            all_preds = torch.cat([all_preds, pred])\n",
    "            \n",
    "    val_acc_epoch = criterion(all_preds.flatten(), all_labels.flatten())\n",
    "    if return_results:\n",
    "        return float(val_acc_epoch), (all_labels, all_preds)\n",
    "    else:\n",
    "        return float(val_acc_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1094557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.1:\n",
      "      Training loss: 261.84\n",
      "      Validation loss: 277.74\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.2:\n",
      "      Training loss: 249.52\n",
      "      Validation loss: 264.28\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.3:\n",
      "      Training loss: 236.28\n",
      "      Validation loss: 249.26\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.4:\n",
      "      Training loss: 221.65\n",
      "      Validation loss: 233.2\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.5:\n",
      "      Training loss: 207.57\n",
      "      Validation loss: 218.84\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.6:\n",
      "      Training loss: 195.08\n",
      "      Validation loss: 206.17\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.7:\n",
      "      Training loss: 183.9\n",
      "      Validation loss: 194.25\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.8:\n",
      "      Training loss: 173.2\n",
      "      Validation loss: 182.92\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.9:\n",
      "      Training loss: 162.9\n",
      "      Validation loss: 171.94\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.10:\n",
      "      Training loss: 153.08\n",
      "      Validation loss: 161.17\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.11:\n",
      "      Training loss: 143.57\n",
      "      Validation loss: 151.15\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.12:\n",
      "      Training loss: 134.9\n",
      "      Validation loss: 141.98\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.13:\n",
      "      Training loss: 127.14\n",
      "      Validation loss: 133.76\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.14:\n",
      "      Training loss: 120.19\n",
      "      Validation loss: 126.29\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.15:\n",
      "      Training loss: 113.85\n",
      "      Validation loss: 119.61\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.16:\n",
      "      Training loss: 108.17\n",
      "      Validation loss: 113.41\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.17:\n",
      "      Training loss: 102.99\n",
      "      Validation loss: 107.71\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.18:\n",
      "      Training loss: 98.23\n",
      "      Validation loss: 102.59\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.19:\n",
      "      Training loss: 93.95\n",
      "      Validation loss: 97.84\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.20:\n",
      "      Training loss: 90.03\n",
      "      Validation loss: 93.47\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.21:\n",
      "      Training loss: 86.46\n",
      "      Validation loss: 89.48\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.22:\n",
      "      Training loss: 83.22\n",
      "      Validation loss: 85.79\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.23:\n",
      "      Training loss: 80.25\n",
      "      Validation loss: 82.35\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.24:\n",
      "      Training loss: 77.49\n",
      "      Validation loss: 79.11\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.25:\n",
      "      Training loss: 74.86\n",
      "      Validation loss: 75.84\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.26:\n",
      "      Training loss: 72.24\n",
      "      Validation loss: 72.66\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.27:\n",
      "      Training loss: 69.85\n",
      "      Validation loss: 69.8\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.28:\n",
      "      Training loss: 67.78\n",
      "      Validation loss: 67.37\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.29:\n",
      "      Training loss: 66.02\n",
      "      Validation loss: 65.28\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.30:\n",
      "      Training loss: 64.54\n",
      "      Validation loss: 63.42\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.31:\n",
      "      Training loss: 63.26\n",
      "      Validation loss: 61.84\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.32:\n",
      "      Training loss: 62.18\n",
      "      Validation loss: 60.44\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.33:\n",
      "      Training loss: 61.24\n",
      "      Validation loss: 59.28\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.34:\n",
      "      Training loss: 60.47\n",
      "      Validation loss: 58.11\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.35:\n",
      "      Training loss: 59.81\n",
      "      Validation loss: 57.07\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.36:\n",
      "      Training loss: 59.2\n",
      "      Validation loss: 56.3\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.37:\n",
      "      Training loss: 58.72\n",
      "      Validation loss: 55.62\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.38:\n",
      "      Training loss: 58.34\n",
      "      Validation loss: 54.9\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.39:\n",
      "      Training loss: 57.97\n",
      "      Validation loss: 54.38\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.40:\n",
      "      Training loss: 57.68\n",
      "      Validation loss: 53.92\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.41:\n",
      "      Training loss: 57.44\n",
      "      Validation loss: 53.48\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.42:\n",
      "      Training loss: 57.24\n",
      "      Validation loss: 53.1\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.43:\n",
      "      Training loss: 57.06\n",
      "      Validation loss: 52.8\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.44:\n",
      "      Training loss: 56.94\n",
      "      Validation loss: 52.48\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.45:\n",
      "      Training loss: 56.82\n",
      "      Validation loss: 52.23\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.46:\n",
      "      Training loss: 56.73\n",
      "      Validation loss: 51.99\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.47:\n",
      "      Training loss: 56.64\n",
      "      Validation loss: 51.82\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.48:\n",
      "      Training loss: 56.58\n",
      "      Validation loss: 51.65\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.49:\n",
      "      Training loss: 56.53\n",
      "      Validation loss: 51.51\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.50:\n",
      "      Training loss: 56.48\n",
      "      Validation loss: 51.42\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.51:\n",
      "      Training loss: 56.46\n",
      "      Validation loss: 51.24\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.52:\n",
      "      Training loss: 56.42\n",
      "      Validation loss: 51.16\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.53:\n",
      "      Training loss: 56.4\n",
      "      Validation loss: 51.1\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.54:\n",
      "      Training loss: 56.39\n",
      "      Validation loss: 50.98\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.55:\n",
      "      Training loss: 56.37\n",
      "      Validation loss: 50.95\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.56:\n",
      "      Training loss: 56.36\n",
      "      Validation loss: 50.9\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.57:\n",
      "      Training loss: 56.35\n",
      "      Validation loss: 50.86\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.58:\n",
      "      Training loss: 56.34\n",
      "      Validation loss: 50.79\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.59:\n",
      "      Training loss: 56.33\n",
      "      Validation loss: 50.73\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.60:\n",
      "      Training loss: 56.33\n",
      "      Validation loss: 50.73\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.61:\n",
      "      Training loss: 56.32\n",
      "      Validation loss: 50.67\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.62:\n",
      "      Training loss: 56.32\n",
      "      Validation loss: 50.65\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.63:\n",
      "      Training loss: 56.32\n",
      "      Validation loss: 50.66\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.64:\n",
      "      Training loss: 56.31\n",
      "      Validation loss: 50.6\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.65:\n",
      "      Training loss: 56.3\n",
      "      Validation loss: 50.6\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.66:\n",
      "      Training loss: 56.3\n",
      "      Validation loss: 50.56\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.67:\n",
      "      Training loss: 56.3\n",
      "      Validation loss: 50.6\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.68:\n",
      "      Training loss: 56.29\n",
      "      Validation loss: 50.57\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.69:\n",
      "      Training loss: 56.29\n",
      "      Validation loss: 50.54\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.70:\n",
      "      Training loss: 56.27\n",
      "      Validation loss: 50.55\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.71:\n",
      "      Training loss: 56.27\n",
      "      Validation loss: 50.54\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.72:\n",
      "      Training loss: 56.26\n",
      "      Validation loss: 50.54\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.73:\n",
      "      Training loss: 56.23\n",
      "      Validation loss: 50.55\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.74:\n",
      "      Training loss: 56.17\n",
      "      Validation loss: 50.56\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.75:\n",
      "      Training loss: 56.04\n",
      "      Validation loss: 50.47\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.76:\n",
      "      Training loss: 55.89\n",
      "      Validation loss: 50.46\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.77:\n",
      "      Training loss: 55.75\n",
      "      Validation loss: 50.49\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.78:\n",
      "      Training loss: 55.49\n",
      "      Validation loss: 50.42\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.79:\n",
      "      Training loss: 55.19\n",
      "      Validation loss: 50.45\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.80:\n",
      "      Training loss: 54.89\n",
      "      Validation loss: 50.3\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.81:\n",
      "      Training loss: 54.54\n",
      "      Validation loss: 50.07\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.82:\n",
      "      Training loss: 54.18\n",
      "      Validation loss: 49.96\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.83:\n",
      "      Training loss: 53.81\n",
      "      Validation loss: 49.85\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.84:\n",
      "      Training loss: 53.4\n",
      "      Validation loss: 49.71\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.85:\n",
      "      Training loss: 52.97\n",
      "      Validation loss: 49.63\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.86:\n",
      "      Training loss: 52.56\n",
      "      Validation loss: 49.49\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.87:\n",
      "      Training loss: 52.2\n",
      "      Validation loss: 49.12\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.88:\n",
      "      Training loss: 51.86\n",
      "      Validation loss: 49.02\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.89:\n",
      "      Training loss: 51.53\n",
      "      Validation loss: 48.65\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.90:\n",
      "      Training loss: 51.23\n",
      "      Validation loss: 48.54\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.91:\n",
      "      Training loss: 51.03\n",
      "      Validation loss: 48.41\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.92:\n",
      "      Training loss: 50.79\n",
      "      Validation loss: 48.33\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.93:\n",
      "      Training loss: 50.56\n",
      "      Validation loss: 48.13\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.94:\n",
      "      Training loss: 50.37\n",
      "      Validation loss: 47.83\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.95:\n",
      "      Training loss: 50.15\n",
      "      Validation loss: 47.99\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.96:\n",
      "      Training loss: 49.91\n",
      "      Validation loss: 47.74\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.97:\n",
      "      Training loss: 49.71\n",
      "      Validation loss: 47.44\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.98:\n",
      "      Training loss: 49.51\n",
      "      Validation loss: 47.52\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.99:\n",
      "      Training loss: 49.41\n",
      "      Validation loss: 47.16\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.100:\n",
      "      Training loss: 49.28\n",
      "      Validation loss: 47.13\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.101:\n",
      "      Training loss: 49.12\n",
      "      Validation loss: 47.01\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.102:\n",
      "      Training loss: 48.82\n",
      "      Validation loss: 47.02\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.103:\n",
      "      Training loss: 48.62\n",
      "      Validation loss: 46.8\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.104:\n",
      "      Training loss: 48.55\n",
      "      Validation loss: 46.66\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.105:\n",
      "      Training loss: 48.43\n",
      "      Validation loss: 46.53\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.106:\n",
      "      Training loss: 48.22\n",
      "      Validation loss: 46.33\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.107:\n",
      "      Training loss: 48.12\n",
      "      Validation loss: 46.31\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.108:\n",
      "      Training loss: 48.04\n",
      "      Validation loss: 46.18\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.109:\n",
      "      Training loss: 47.92\n",
      "      Validation loss: 46.21\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.110:\n",
      "      Training loss: 47.85\n",
      "      Validation loss: 45.8\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.111:\n",
      "      Training loss: 47.68\n",
      "      Validation loss: 45.83\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.112:\n",
      "      Training loss: 47.6\n",
      "      Validation loss: 45.7\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.113:\n",
      "      Training loss: 47.53\n",
      "      Validation loss: 45.42\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.114:\n",
      "      Training loss: 47.43\n",
      "      Validation loss: 45.17\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.115:\n",
      "      Training loss: 47.33\n",
      "      Validation loss: 44.87\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.116:\n",
      "      Training loss: 47.17\n",
      "      Validation loss: 44.79\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.117:\n",
      "      Training loss: 47.09\n",
      "      Validation loss: 44.82\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.118:\n",
      "      Training loss: 46.96\n",
      "      Validation loss: 44.34\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.119:\n",
      "      Training loss: 46.86\n",
      "      Validation loss: 44.28\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.120:\n",
      "      Training loss: 46.74\n",
      "      Validation loss: 44.08\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.121:\n",
      "      Training loss: 46.69\n",
      "      Validation loss: 44.11\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.122:\n",
      "      Training loss: 46.56\n",
      "      Validation loss: 43.76\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.123:\n",
      "      Training loss: 46.36\n",
      "      Validation loss: 43.7\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.124:\n",
      "      Training loss: 46.12\n",
      "      Validation loss: 43.29\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.125:\n",
      "      Training loss: 45.93\n",
      "      Validation loss: 43.16\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.126:\n",
      "      Training loss: 45.86\n",
      "      Validation loss: 43.12\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.127:\n",
      "      Training loss: 45.67\n",
      "      Validation loss: 42.9\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.128:\n",
      "      Training loss: 45.59\n",
      "      Validation loss: 42.65\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.129:\n",
      "      Training loss: 45.49\n",
      "      Validation loss: 42.67\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.130:\n",
      "      Training loss: 45.27\n",
      "      Validation loss: 42.53\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.131:\n",
      "      Training loss: 45.17\n",
      "      Validation loss: 42.12\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.132:\n",
      "      Training loss: 45.02\n",
      "      Validation loss: 42.38\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.133:\n",
      "      Training loss: 44.95\n",
      "      Validation loss: 42.05\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.134:\n",
      "      Training loss: 44.83\n",
      "      Validation loss: 41.95\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.135:\n",
      "      Training loss: 44.86\n",
      "      Validation loss: 42.05\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.136:\n",
      "      Training loss: 44.66\n",
      "      Validation loss: 41.81\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.137:\n",
      "      Training loss: 44.62\n",
      "      Validation loss: 41.79\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.138:\n",
      "      Training loss: 44.47\n",
      "      Validation loss: 41.62\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.139:\n",
      "      Training loss: 44.44\n",
      "      Validation loss: 41.37\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.140:\n",
      "      Training loss: 44.38\n",
      "      Validation loss: 41.43\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.141:\n",
      "      Training loss: 44.15\n",
      "      Validation loss: 41.24\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.142:\n",
      "      Training loss: 44.07\n",
      "      Validation loss: 41.28\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.143:\n",
      "      Training loss: 43.9\n",
      "      Validation loss: 41.03\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.144:\n",
      "      Training loss: 43.83\n",
      "      Validation loss: 40.8\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.145:\n",
      "      Training loss: 43.75\n",
      "      Validation loss: 40.77\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.146:\n",
      "      Training loss: 43.62\n",
      "      Validation loss: 41.0\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.147:\n",
      "      Training loss: 43.66\n",
      "      Validation loss: 40.75\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.148:\n",
      "      Training loss: 43.46\n",
      "      Validation loss: 41.3\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.149:\n",
      "      Training loss: 43.43\n",
      "      Validation loss: 40.55\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.150:\n",
      "      Training loss: 43.33\n",
      "      Validation loss: 40.34\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.151:\n",
      "      Training loss: 43.34\n",
      "      Validation loss: 40.26\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.152:\n",
      "      Training loss: 43.19\n",
      "      Validation loss: 40.44\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.153:\n",
      "      Training loss: 43.07\n",
      "      Validation loss: 40.23\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.154:\n",
      "      Training loss: 42.89\n",
      "      Validation loss: 40.23\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.155:\n",
      "      Training loss: 42.84\n",
      "      Validation loss: 40.07\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.156:\n",
      "      Training loss: 42.77\n",
      "      Validation loss: 40.15\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.157:\n",
      "      Training loss: 42.65\n",
      "      Validation loss: 40.07\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.158:\n",
      "      Training loss: 42.62\n",
      "      Validation loss: 40.07\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.159:\n",
      "      Training loss: 42.4\n",
      "      Validation loss: 39.78\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.160:\n",
      "      Training loss: 42.3\n",
      "      Validation loss: 39.63\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.161:\n",
      "      Training loss: 42.28\n",
      "      Validation loss: 39.72\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.162:\n",
      "      Training loss: 42.26\n",
      "      Validation loss: 39.73\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.163:\n",
      "      Training loss: 42.12\n",
      "      Validation loss: 39.36\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.164:\n",
      "      Training loss: 42.09\n",
      "      Validation loss: 39.32\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.165:\n",
      "      Training loss: 41.94\n",
      "      Validation loss: 39.38\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.166:\n",
      "      Training loss: 41.8\n",
      "      Validation loss: 39.14\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.167:\n",
      "      Training loss: 41.82\n",
      "      Validation loss: 39.21\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.168:\n",
      "      Training loss: 41.69\n",
      "      Validation loss: 39.02\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.169:\n",
      "      Training loss: 41.62\n",
      "      Validation loss: 39.32\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.170:\n",
      "      Training loss: 41.69\n",
      "      Validation loss: 38.94\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.171:\n",
      "      Training loss: 41.56\n",
      "      Validation loss: 38.79\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.172:\n",
      "      Training loss: 41.44\n",
      "      Validation loss: 38.87\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.173:\n",
      "      Training loss: 41.36\n",
      "      Validation loss: 38.77\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.174:\n",
      "      Training loss: 41.27\n",
      "      Validation loss: 38.62\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.175:\n",
      "      Training loss: 41.22\n",
      "      Validation loss: 38.43\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.176:\n",
      "      Training loss: 41.17\n",
      "      Validation loss: 38.48\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.177:\n",
      "      Training loss: 41.1\n",
      "      Validation loss: 38.45\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.178:\n",
      "      Training loss: 41.22\n",
      "      Validation loss: 38.43\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.179:\n",
      "      Training loss: 41.1\n",
      "      Validation loss: 38.25\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.180:\n",
      "      Training loss: 41.09\n",
      "      Validation loss: 38.23\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.181:\n",
      "      Training loss: 40.91\n",
      "      Validation loss: 38.25\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.182:\n",
      "      Training loss: 40.77\n",
      "      Validation loss: 37.9\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No.183:\n",
      "      Training loss: 40.75\n",
      "      Validation loss: 38.38\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.184:\n",
      "      Training loss: 40.64\n",
      "      Validation loss: 37.88\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.185:\n",
      "      Training loss: 40.62\n",
      "      Validation loss: 37.99\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.186:\n",
      "      Training loss: 40.61\n",
      "      Validation loss: 38.16\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.187:\n",
      "      Training loss: 40.52\n",
      "      Validation loss: 38.07\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.188:\n",
      "      Training loss: 40.45\n",
      "      Validation loss: 37.95\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.189:\n",
      "      Training loss: 40.46\n",
      "      Validation loss: 38.02\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.190:\n",
      "      Training loss: 40.41\n",
      "      Validation loss: 37.72\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.191:\n",
      "      Training loss: 40.32\n",
      "      Validation loss: 37.72\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.192:\n",
      "      Training loss: 40.25\n",
      "      Validation loss: 37.98\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.193:\n",
      "      Training loss: 40.19\n",
      "      Validation loss: 37.94\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.194:\n",
      "      Training loss: 40.12\n",
      "      Validation loss: 37.62\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.195:\n",
      "      Training loss: 40.05\n",
      "      Validation loss: 37.55\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.196:\n",
      "      Training loss: 39.99\n",
      "      Validation loss: 37.55\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.197:\n",
      "      Training loss: 39.9\n",
      "      Validation loss: 37.62\n",
      "      Best training model found.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.198:\n",
      "      Training loss: 39.9\n",
      "      Validation loss: 37.7\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.199:\n",
      "      Training loss: 39.8\n",
      "      Validation loss: 37.49\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Epoch No.200:\n",
      "      Training loss: 39.77\n",
      "      Validation loss: 37.31\n",
      "      Best training model found.\n",
      "      Best validation model found and saved.\n",
      "---------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# initiate the model\n",
    "rp_MLP = RP_MLP(feature_dim = 8)\n",
    "# define optimizer\n",
    "opt = optim.Adam(rp_MLP.parameters(), lr = 1e-3)\n",
    "#hyperparas\n",
    "total_epoch = 200\n",
    "model_save = 'best_RP_MLP.pt'\n",
    "\n",
    "# Main Func\n",
    "train_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    train_loss_epoch = train(rp_MLP,train_loader, opt, F.mse_loss)\n",
    "    val_acc_epoch,  detail = validate(rp_MLP,val_loader, F.mse_loss, True)\n",
    "    #print(detail)\n",
    "    train_loss.append(train_loss_epoch)\n",
    "    val_acc.append(val_acc_epoch)\n",
    "    print(f'Epoch No.{epoch}:')\n",
    "    print(f'      Training loss: {str(round(train_loss_epoch, 2))}')\n",
    "    print(f'      Validation loss: {str(round(val_acc_epoch, 2))}')\n",
    "    \n",
    "    if train_loss[-1] == np.min(train_loss):\n",
    "        print('      Best training model found.')\n",
    "    if val_acc[-1] == np.min(val_acc):\n",
    "        # save current best model on validation set\n",
    "        with open(model_save, 'wb') as f:\n",
    "            torch.save(rp_MLP.state_dict(), f)\n",
    "            print('      Best validation model found and saved.')\n",
    "    \n",
    "    print('-' * 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae5e9640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices are :\n",
      " tensor([ 13.1860,  20.8905,  20.7936,   7.5810,   7.3815,  22.3250,   6.8400,\n",
      "         14.0600,  18.7856,   5.2250,   5.4625,  15.9200,   5.4625,  15.9200,\n",
      "         16.1289,   7.5050,  16.0693,  13.9200,  19.9500,  23.7405,  19.3800,\n",
      "         13.1241,  18.7625,  17.8600,  18.7625,  17.8600,   4.1800,  21.5000,\n",
      "         15.1000,  14.2405,  15.0670,  18.8860,   4.6360,   6.0800,   3.7050,\n",
      "         16.5300,   3.7050,  16.5300,  14.4772,   5.0350,  34.2000,   9.5000,\n",
      "         14.7250,  21.4700,  14.3250,  27.0750,   6.5550,   8.4550,   6.5550,\n",
      "          8.4550,  14.3900,  20.6625,  27.3600,   7.0775,  15.1905,  17.5750,\n",
      "          9.2625,  12.3569,  13.6315,  14.2405,  13.6315,  14.2405,  18.6500,\n",
      "         16.6250,  13.9595,  11.5420,  13.2050,  39.2000,  19.9500,  16.3562,\n",
      "         11.8206,  13.9270,  11.8206,  13.9270,  18.9050,  15.1141,  18.6200,\n",
      "         18.9430,   5.5575,  20.9000,  20.3000,  28.5000,  11.8750,  16.9150,\n",
      "         11.8750,  16.9150,  21.8310,   6.6500,   5.5100,  14.7250,  26.1250,\n",
      "         14.2405,  16.2350,  12.8250,  29.4500,  17.7555,  29.4500,  17.7555,\n",
      "         12.7460,  20.9000,  15.0860,   5.6050,  16.1190,   8.7400,   4.6550,\n",
      "         11.0000,   4.2655,  10.9250,   4.2655,  10.9250,   9.5000,  28.6500,\n",
      "         21.7550,  33.4250,   5.3675,  10.4500, 100.0000,   4.7489,  17.0000,\n",
      "         21.8500], dtype=torch.float64) \n",
      "With their predictions as :\n",
      " tensor([16.6147, 18.2804, 16.3319, 16.6610, 12.4859, 13.7452,  9.1421, 14.7967,\n",
      "         9.7222, 18.1405, 20.7262, 10.9310, 20.7262, 10.9310, 14.8817, 17.8944,\n",
      "        19.4074, 11.6487, 13.3912, 18.2152, 12.5970, 12.7843, 13.2053, 16.6502,\n",
      "        13.2053, 16.6502, 14.8817, 14.8810, 12.5121, 14.8926, 12.5716, 14.9043,\n",
      "        14.8817, 14.8817, 19.0875, 16.7634, 19.0875, 16.7634,  7.8891, 19.1555,\n",
      "         6.9436, 21.2013, 15.3485, 14.5422, 15.9114, 15.9166, 13.6805, 14.8817,\n",
      "        13.6805, 14.8817, 10.3266, 13.7402, 14.2957,  5.7765, 22.6843, 14.8797,\n",
      "        16.6511, 14.2667, 14.8625, 14.8817, 14.8625, 14.8817, 11.7393, 13.5221,\n",
      "        14.1074, 17.9052, 16.6132,  9.7307, 14.4933, 11.3092, 11.4107, 11.5149,\n",
      "        11.4107, 11.5149,  8.9696,  9.9479, 15.3340, 14.0368, 11.9360, 16.6214,\n",
      "        16.2317, 22.9003, 12.7919, 14.8817, 12.7919, 14.8817, 12.3336, 16.3041,\n",
      "        17.8177, 16.0627, 12.5717, 16.7450, 13.1419, 20.9636, 17.0337, 14.8817,\n",
      "        17.0337, 14.8817, 11.1306, 21.1623, 21.4490, 12.5796, 13.8510,  9.6112,\n",
      "        19.1545, 16.7575,  7.1744, 12.5966,  7.1744, 12.5966, 14.8818, 13.7936,\n",
      "        19.0991, 14.8815, 14.9073, 15.6517, 13.4723, 16.6145,  9.0397, 14.9319])\n",
      "Final train loss 39.47 | val loss 37.31 | test loss 102.68\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "def evaluation(model, loader, criterion, istest = False):\n",
    "    all_labels = torch.tensor([])\n",
    "    all_preds = torch.tensor([])\n",
    "    with torch.no_grad():\n",
    "        for batch_id, [data, labels] in enumerate(loader):\n",
    "            pred = model(data)\n",
    "            all_labels = torch.cat([all_labels, labels])\n",
    "            all_preds = torch.cat([all_preds, pred])\n",
    "            \n",
    "    val_acc_epoch = criterion(all_preds.flatten(), all_labels.flatten())\n",
    "    if istest:\n",
    "        return float(val_acc_epoch), (all_labels, all_preds)\n",
    "    else:\n",
    "        return float(val_acc_epoch)\n",
    "# Load datasets\n",
    "train_loader = DataLoader(dataset_pipeline(tr_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False\n",
    "                         )\n",
    "val_loader = DataLoader(dataset_pipeline(val_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False\n",
    "                         )\n",
    "test_loader = DataLoader(dataset_pipeline(test_name),\n",
    "                          batch_size = batch_size,\n",
    "                          shuffle = False\n",
    "                         )\n",
    "# Load model weights\n",
    "rp_MLP.load_state_dict(torch.load(model_save))\n",
    "\n",
    "final_train_acc = evaluation(rp_MLP, train_loader, F.mse_loss)\n",
    "final_val_acc = evaluation(rp_MLP, val_loader, F.mse_loss)\n",
    "final_test_acc, details = evaluation(rp_MLP, test_loader, F.mse_loss, istest = True)\n",
    "print('Prices are :\\n', details[0], '\\nWith their predictions as :\\n', detail[1].flatten())\n",
    "print(f'Final train loss {str(round(final_train_acc, 2))} | val loss {str(round(final_val_acc, 2))} | test loss {str(round(final_test_acc, 2))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883628ce",
   "metadata": {},
   "source": [
    "From the above analyse, we can see that the rarity attributes do have relationship with their prices. And the data type is prety suitable for the MLP to deal with.\n",
    "\n",
    "Buyers do tend to buy more fancy monkeys with interesting rare features, which really makes sense."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
